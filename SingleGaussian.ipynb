{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generating the Data",
   "id": "81192a2dd0eae050"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "\n",
    "def get_train_test_data(n=100, seed=11121):\n",
    "    # Generate all data\n",
    "    data_all = datasets.make_moons(n, random_state=seed)[0]\n",
    "\n",
    "    # Split into train/test data\n",
    "    train_n = math.floor(0.8 * n)\n",
    "    train_data = data_all[:train_n]\n",
    "    test_data = data_all[train_n:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "train_data, test_data = get_train_test_data()"
   ],
   "id": "fcd7f289e739f7d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define the Gaussian PDF\n",
    "\n",
    "For a point $ x $, the PDF for a multivariate Gaussian distribution is:\n",
    "$$\n",
    "   p(x) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu)\\right)\n",
    "$$\n",
    "This formula includes:\n",
    "   - $ |\\Sigma| $: Determinant of the covariance matrix.\n",
    "   - $ \\Sigma^{-1} $: Inverse of the covariance matrix.\n",
    "   - Exponential term based on the squared distance between $ x $ and $ \\mu $.\n",
    "\n",
    "as found on [Wikipedia](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)\n",
    "\n",
    "\n",
    "The Single Gaussian Model assumes the data follows a Gaussian distribution with these parameters. Since the actual data distribution is not Gaussian, this model will only be an approximation."
   ],
   "id": "16738eef3b40fefc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_mean_and_covariance(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    covariance = np.cov(data, rowvar=False)\n",
    "    return mean, covariance\n",
    "\n",
    "def gaussian_pdf(x, mean, covariance):\n",
    "    d = len(mean)\n",
    "    det_covariance = np.linalg.det(covariance)\n",
    "    inv_covariance = np.linalg.inv(covariance)\n",
    "    norm_factor = 1 / ((2 * np.pi) ** (d / 2) * det_covariance ** 0.5)\n",
    "    \n",
    "    diff = x - mean\n",
    "    exponent = -0.5 * np.dot(np.dot(diff.T, inv_covariance), diff)\n",
    "    \n",
    "    return norm_factor * np.exp(exponent)\n",
    "\n",
    "def sample_gaussian(mean, covariance, n=1):\n",
    "    z = np.random.normal(size=(n, len(mean)))\n",
    "    \n",
    "    # Step 2: Transform the samples to match the Gaussian distribution\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
    "    Lambda_sqrt = np.diag(np.sqrt(eigenvalues))\n",
    "    \n",
    "    transformed_samples = z @ Lambda_sqrt @ eigenvectors.T + mean\n",
    "    \n",
    "    return transformed_samples"
   ],
   "id": "3caf5677b409d5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fit the Gaussian model to the training data",
   "id": "73049a13ac329419"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mean, covariance = calculate_mean_and_covariance(train_data)",
   "id": "f897aa158bdbe2ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 4: Calculate PDF values for the test data",
   "id": "60d645949e802c16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pdf_values = np.array([gaussian_pdf(x, mean, covariance) for x in test_data])\n",
    "print(\"PDF Values for test data:\", pdf_values)"
   ],
   "id": "5a551cb395d0e3e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting",
   "id": "affe6ba49edeaef7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define grid over the data range for contour plot\n",
    "x_min, x_max = train_data[:, 0].min() - 1, train_data[:, 0].max() + 1\n",
    "y_min, y_max = train_data[:, 1].min() - 1, train_data[:, 1].max() + 1\n",
    "x_grid, y_grid = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Calculate PDF values over the grid for the contour plot\n",
    "pdf_values = np.array([\n",
    "    gaussian_pdf(np.array([x, y]), mean, covariance)\n",
    "    for x, y in zip(np.ravel(x_grid), np.ravel(y_grid))\n",
    "])\n",
    "pdf_values = pdf_values.reshape(x_grid.shape)"
   ],
   "id": "c90dc3c5b70e3bca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plot (i): Density as contour plot",
   "id": "629759fab8728e48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(x_grid, y_grid, pdf_values, levels=10, cmap=\"viridis\", alpha=0.7)\n",
    "plt.colorbar(label=\"PDF Value\")\n",
    "plt.scatter(mean[0], mean[1], color=\"red\", marker=\"x\", s=100, label=\"Mean\")\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], color=\"blue\", s=10, alpha=0.5, label=\"Training Data\")\n",
    "plt.title(\"Gaussian PDF Contour Plot with Mean\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()"
   ],
   "id": "e57b545981432bed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot (ii): Generate and plot synthetic dataset from Gaussian\n",
    "\n",
    "NEed to generate new samples from the fitted Gaussian model, based on the mean and covariance derived training data, to visualize what the Single Gaussian model predicts the data looks like"
   ],
   "id": "729c15fa61652be8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "generated_data = sample_gaussian(mean, covariance, n=100)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(generated_data[:, 0], generated_data[:, 1], color=\"purple\", s=10, label=\"Generated Data\")\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], color=\"blue\", s=10, alpha=0.5, label=\"Training Data\")\n",
    "plt.title(\"Generated Data from Single Gaussian Model\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c27e1d241ac1c394"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Strengths\n",
    "- **Simplicity and Efficiency**: The Single Gaussian model is computationally efficient (this notebook runs fast) and easy to implement (only one function is needed essentially)\n",
    "- **Distribution Approximation**: For data that is roughly unimodal and symmetric, the Gaussian is a decent approximation\n",
    "\n",
    "\n",
    "### Weaknesses\n",
    "- **Inflexibility for Complex Shapes**: The Single Gaussian model is limited to a single peak and fails to capture multimodal or non-linear distributions, such as the \"moons\" data, which has a distinct shape.\n",
    "- **Poor Fit for Non-Gaussian Data**: It assumes that data is symmetrically distributed around a mean, making it unsuitable for datasets with clusters or irregular shapes, leading to an inaccurate representation.\n",
    "\n",
    "We clearly see that the model is not appropriate for this. However, we can use this as a reference  for comparing more complex models and to see improvements or limitations when using other methods like GMM or KDE."
   ],
   "id": "d214af6397af508d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MMD Evaluation",
   "id": "8f82a49d1ccadd0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from MMD import calculate_mmd\n",
    "\n",
    "reference_data = test_data\n",
    "\n",
    "# Calculate MMD between generated samples and reference test data\n",
    "mmd_results = calculate_mmd(reference_data, generated_data, bandwidths=[1.0, 2.0])\n",
    "\n",
    "print(f'Single Gaussian MMD: {mmd_results}')\n",
    "for kernel, mmd_value in mmd_results.items():\n",
    "    print(f\"MMD using {kernel} kernel: {mmd_value}\")\n",
    "\n"
   ],
   "id": "760dfbd19dad85c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
